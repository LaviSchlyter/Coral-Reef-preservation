{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4\n",
    "## Extende version of Data collection and processing of the Pacific Ocean\n",
    "\n",
    "\n",
    "\n",
    "In this notebook, the following data is collected using API's: \n",
    "- Solar radiation\n",
    "- Wind speed\n",
    "- Chlorophyll concentration \n",
    "\n",
    "We also merge the data onto the dataframe for the following downloaded data:\n",
    "- SST\n",
    "- DHW\n",
    "- Depth \n",
    "\n",
    "Note: This Notebook is computationally and time expensive !\n",
    "It is neither optimized, much of it is also in the Notebook 2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lavinia/.local/lib/python3.8/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.0-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Importing packages\n",
    "import gdal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from io import StringIO\n",
    "from shapely.geometry import Point\n",
    "import osr\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import cKDTree\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "sys.path.insert(0, os.path.abspath(''))\n",
    "\n",
    "import data_processing_helper as dp\n",
    "import practical_functions as pf\n",
    "import xarray as xr\n",
    "import pygrib\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import netCDF4 as nc\n",
    "import requests as rq\n",
    "import shapely\n",
    "from shapely import wkt\n",
    "from shapely.wkt import loads\n",
    "from osgeo import gdal\n",
    "plt.style.use('ggplot') # use ggplot style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Shapefiles for the Pacific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_AUS = gpd.read_file('../Data/Reefs/shp_GBR/Reefs_GBR.shp')\n",
    "drop_cols_shape = ['left', 'top', 'right', 'bottom', 'AREA']\n",
    "gdf_IND = gpd.read_file('../Data/Reefs/shp_indonesia/indonesia.shp').drop(columns = drop_cols_shape)\n",
    "gdf_TLS = gpd.read_file('../Data/Reefs/shp_timorleste/timorleste.shp').drop(columns = drop_cols_shape)\n",
    "gdf_SLB = gpd.read_file('../Data/Reefs/shp_solomon/solomon.shp').drop(columns = drop_cols_shape)\n",
    "\n",
    "# Combining the shapefiles\n",
    "gdf_PAC = gpd.GeoDataFrame(pd.concat([gdf_AUS, gdf_IND, gdf_TLS, gdf_SLB]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Plotting the the different shapes\n",
    "gdf_PAC.plot(edgecolor = \"blacK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Survey folder\n",
    "It contains the coordinates of the Survey and the percentage of algae, corals, soft_corals or other_invertebrates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surveyid</th>\n",
       "      <th>transectid</th>\n",
       "      <th>surveydate</th>\n",
       "      <th>ocean</th>\n",
       "      <th>country</th>\n",
       "      <th>folder_name</th>\n",
       "      <th>lat_start</th>\n",
       "      <th>lng_start</th>\n",
       "      <th>lat_end</th>\n",
       "      <th>lng_end</th>\n",
       "      <th>pr_hard_coral</th>\n",
       "      <th>pr_algae</th>\n",
       "      <th>pr_soft_coral</th>\n",
       "      <th>pr_oth_invert</th>\n",
       "      <th>pr_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>10001</td>\n",
       "      <td>20120916</td>\n",
       "      <td>PAC</td>\n",
       "      <td>AUS</td>\n",
       "      <td>PAC_AUS_10001_201209</td>\n",
       "      <td>-16.189023</td>\n",
       "      <td>145.898104</td>\n",
       "      <td>-16.191761</td>\n",
       "      <td>145.894088</td>\n",
       "      <td>0.1856</td>\n",
       "      <td>0.3724</td>\n",
       "      <td>0.2710</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>10002</td>\n",
       "      <td>20120917</td>\n",
       "      <td>PAC</td>\n",
       "      <td>AUS</td>\n",
       "      <td>PAC_AUS_10002_201209</td>\n",
       "      <td>-16.189303</td>\n",
       "      <td>145.898254</td>\n",
       "      <td>-16.175947</td>\n",
       "      <td>145.889736</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.3079</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>10003</td>\n",
       "      <td>20120918</td>\n",
       "      <td>PAC</td>\n",
       "      <td>AUS</td>\n",
       "      <td>PAC_AUS_10003_201209</td>\n",
       "      <td>-16.175768</td>\n",
       "      <td>145.891676</td>\n",
       "      <td>-16.181218</td>\n",
       "      <td>145.888904</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>0.5653</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004</td>\n",
       "      <td>10004</td>\n",
       "      <td>20120920</td>\n",
       "      <td>PAC</td>\n",
       "      <td>AUS</td>\n",
       "      <td>PAC_AUS_10004_201209</td>\n",
       "      <td>-16.536645</td>\n",
       "      <td>147.806796</td>\n",
       "      <td>-16.524287</td>\n",
       "      <td>147.843325</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>0.5706</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.2748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10005</td>\n",
       "      <td>10005</td>\n",
       "      <td>20120920</td>\n",
       "      <td>PAC</td>\n",
       "      <td>AUS</td>\n",
       "      <td>PAC_AUS_10005_201209</td>\n",
       "      <td>-16.529216</td>\n",
       "      <td>147.802582</td>\n",
       "      <td>-16.521689</td>\n",
       "      <td>147.836180</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.7894</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.1201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   surveyid  transectid  surveydate ocean country           folder_name  \\\n",
       "0     10001       10001    20120916   PAC     AUS  PAC_AUS_10001_201209   \n",
       "1     10002       10002    20120917   PAC     AUS  PAC_AUS_10002_201209   \n",
       "2     10003       10003    20120918   PAC     AUS  PAC_AUS_10003_201209   \n",
       "3     10004       10004    20120920   PAC     AUS  PAC_AUS_10004_201209   \n",
       "4     10005       10005    20120920   PAC     AUS  PAC_AUS_10005_201209   \n",
       "\n",
       "   lat_start   lng_start    lat_end     lng_end  pr_hard_coral  pr_algae  \\\n",
       "0 -16.189023  145.898104 -16.191761  145.894088         0.1856    0.3724   \n",
       "1 -16.189303  145.898254 -16.175947  145.889736         0.1364    0.4766   \n",
       "2 -16.175768  145.891676 -16.181218  145.888904         0.2475    0.5653   \n",
       "3 -16.536645  147.806796 -16.524287  147.843325         0.1242    0.5706   \n",
       "4 -16.529216  147.802582 -16.521689  147.836180         0.0781    0.7894   \n",
       "\n",
       "   pr_soft_coral  pr_oth_invert  pr_other  \n",
       "0         0.2710         0.0010    0.1700  \n",
       "1         0.3079         0.0020    0.0771  \n",
       "2         0.0747         0.0207    0.0917  \n",
       "3         0.0279         0.0023    0.2748  \n",
       "4         0.0096         0.0029    0.1201  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Survey_global = pd.read_csv(\"../Data/Reefs/seaviewsurvey_surveys.csv\")\n",
    "Survey_global.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have a total of : 421  Surveys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surveyid</th>\n",
       "      <th>transectid</th>\n",
       "      <th>surveydate</th>\n",
       "      <th>ocean</th>\n",
       "      <th>country</th>\n",
       "      <th>folder_name</th>\n",
       "      <th>lat_start</th>\n",
       "      <th>lng_start</th>\n",
       "      <th>lat_end</th>\n",
       "      <th>lng_end</th>\n",
       "      <th>pr_hard_coral</th>\n",
       "      <th>pr_algae</th>\n",
       "      <th>pr_soft_coral</th>\n",
       "      <th>pr_oth_invert</th>\n",
       "      <th>pr_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>10001</td>\n",
       "      <td>20120916</td>\n",
       "      <td>PAC</td>\n",
       "      <td>AUS</td>\n",
       "      <td>PAC_AUS_10001_201209</td>\n",
       "      <td>-16.189023</td>\n",
       "      <td>145.898104</td>\n",
       "      <td>-16.191761</td>\n",
       "      <td>145.894088</td>\n",
       "      <td>0.1856</td>\n",
       "      <td>0.3724</td>\n",
       "      <td>0.2710</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>10002</td>\n",
       "      <td>20120917</td>\n",
       "      <td>PAC</td>\n",
       "      <td>AUS</td>\n",
       "      <td>PAC_AUS_10002_201209</td>\n",
       "      <td>-16.189303</td>\n",
       "      <td>145.898254</td>\n",
       "      <td>-16.175947</td>\n",
       "      <td>145.889736</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.3079</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>10003</td>\n",
       "      <td>20120918</td>\n",
       "      <td>PAC</td>\n",
       "      <td>AUS</td>\n",
       "      <td>PAC_AUS_10003_201209</td>\n",
       "      <td>-16.175768</td>\n",
       "      <td>145.891676</td>\n",
       "      <td>-16.181218</td>\n",
       "      <td>145.888904</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>0.5653</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004</td>\n",
       "      <td>10004</td>\n",
       "      <td>20120920</td>\n",
       "      <td>PAC</td>\n",
       "      <td>AUS</td>\n",
       "      <td>PAC_AUS_10004_201209</td>\n",
       "      <td>-16.536645</td>\n",
       "      <td>147.806796</td>\n",
       "      <td>-16.524287</td>\n",
       "      <td>147.843325</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>0.5706</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.2748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10005</td>\n",
       "      <td>10005</td>\n",
       "      <td>20120920</td>\n",
       "      <td>PAC</td>\n",
       "      <td>AUS</td>\n",
       "      <td>PAC_AUS_10005_201209</td>\n",
       "      <td>-16.529216</td>\n",
       "      <td>147.802582</td>\n",
       "      <td>-16.521689</td>\n",
       "      <td>147.836180</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.7894</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.1201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   surveyid  transectid  surveydate ocean country           folder_name  \\\n",
       "0     10001       10001    20120916   PAC     AUS  PAC_AUS_10001_201209   \n",
       "1     10002       10002    20120917   PAC     AUS  PAC_AUS_10002_201209   \n",
       "2     10003       10003    20120918   PAC     AUS  PAC_AUS_10003_201209   \n",
       "3     10004       10004    20120920   PAC     AUS  PAC_AUS_10004_201209   \n",
       "4     10005       10005    20120920   PAC     AUS  PAC_AUS_10005_201209   \n",
       "\n",
       "   lat_start   lng_start    lat_end     lng_end  pr_hard_coral  pr_algae  \\\n",
       "0 -16.189023  145.898104 -16.191761  145.894088         0.1856    0.3724   \n",
       "1 -16.189303  145.898254 -16.175947  145.889736         0.1364    0.4766   \n",
       "2 -16.175768  145.891676 -16.181218  145.888904         0.2475    0.5653   \n",
       "3 -16.536645  147.806796 -16.524287  147.843325         0.1242    0.5706   \n",
       "4 -16.529216  147.802582 -16.521689  147.836180         0.0781    0.7894   \n",
       "\n",
       "   pr_soft_coral  pr_oth_invert  pr_other  \n",
       "0         0.2710         0.0010    0.1700  \n",
       "1         0.3079         0.0020    0.0771  \n",
       "2         0.0747         0.0207    0.0917  \n",
       "3         0.0279         0.0023    0.2748  \n",
       "4         0.0096         0.0029    0.1201  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Survey = Survey_global[(Survey_global[\"country\"] == \"AUS\") | (Survey_global[\"country\"] == \"IDN\") | (Survey_global[\"country\"] == \"TLS\")| (Survey_global[\"country\"] == \"SLB\")]\n",
    "print(\"We now have a total of :\",Survey.shape[0], \" Surveys\")\n",
    "Survey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change date format \n",
    "Survey['surveydate'] = pd.to_datetime(Survey['surveydate'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AUS    261\n",
       "IDN    114\n",
       "TLS     26\n",
       "SLB     20\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make pacific survey into GeoDataFrame\n",
    "gSurvey = gpd.GeoDataFrame(Survey, geometry = gpd.points_from_xy(Survey.lat_start, Survey.lng_start))\n",
    "gSurvey[\"country\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most surveys were taken in Australia followed by Indonesia. With a total of 421 surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only month and year\n",
    "gSurvey['surveydate'] = gSurvey['surveydate'].dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended Wind speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load xarray\n",
    "ds_wind = xr.open_dataset(\"../Data/Environmental_data/wind_monthly.nc\")\n",
    "\n",
    "# Make dataframe\n",
    "df_wind = ds_wind.to_dataframe()\n",
    "\n",
    "# Rename and reset longitude and latitude index\n",
    "df_wind.rename(columns = {\"si10\":\"wind_speed\"}, inplace = True)\n",
    "\n",
    "df_indx = df_wind.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wind.reset_index(inplace = True)\n",
    "\n",
    "# Make into GeoDataFrame\n",
    "gdf_wind = gpd.GeoDataFrame(df_wind, geometry=gpd.points_from_xy(df_wind.latitude, df_wind.longitude))\n",
    "\n",
    "# Keep only month and year\n",
    "gdf_wind[\"time\"] = gdf_wind[\"time\"].dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unecessary columns\n",
    "gdf_wind.drop(columns = ['latitude', 'longitude', 'number', 'step', 'surface',\n",
    "       'valid_time'], inplace = True)\n",
    "gSurvey.drop(columns = ['surveyid', 'ocean', \n",
    "       'folder_name', 'lat_end', 'lng_end',\n",
    "       'pr_hard_coral', 'pr_algae', 'pr_soft_coral', 'pr_oth_invert',\n",
    "       'pr_other'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the dates which are unique within the survey (month and year)\n",
    "dates_surveys = gSurvey['surveydate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through the different dates and places and find the closest wind speed at each Survey point\n",
    "frames_all = dp.merge_(gSurvey,gdf_wind, dates_surveys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add wind_speed to geoframe\n",
    "gSurvey[\"wind_speed\"] = frames_all[\"wind_speed\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Survey.drop(columns = ['surveyid', 'ocean', 'country',\n",
    "       'folder_name', 'lat_start', 'lng_start', 'lat_end', 'lng_end',\n",
    "        'geometry'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with Survey\n",
    "df_merge_w = pd.merge(Survey, gSurvey,on = [\"surveydate\",\"transectid\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    411\n",
      "4      5\n",
      "dtype: int64\n",
      "You have 5 surveys with 4 duplicates...remove to ease computation\n"
     ]
    }
   ],
   "source": [
    "dups_sur_trans = df_merge_w.pivot_table(index=['surveydate','transectid'], aggfunc='size')\n",
    "print (dups_sur_trans.value_counts())\n",
    "print(\"You have 5 surveys with 4 duplicates...remove to ease computation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surveydate  transectid\n",
       "2014-05     12029         4\n",
       "2018-06     32003         4\n",
       "            32024         4\n",
       "            32026         4\n",
       "            32030         4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dups_sur_trans[dups_sur_trans == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I drop the duplicates on time and transectid, indeed I could just take the mean of them instead of \n",
    "# keeping only first value\n",
    "df_mer_w = df_merge_w.drop_duplicates(subset=[\"surveydate\",\"transectid\"], keep=\"first\", inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ck(gdA, gdB):\n",
    "\n",
    "    nA = np.array(list(gdA.geometry.apply(lambda x: (x.x, x.y))))\n",
    "    nB = np.array(list(gdB.geometry.apply(lambda x: (x.x, x.y))))\n",
    "    btree = cKDTree(nB)\n",
    "    dist, idx = btree.query(nA, k=1)\n",
    "    gdB_nearest = gdB.iloc[idx].drop(columns=\"geometry\").reset_index(drop=True)\n",
    "    \n",
    "    gdf = pd.concat(\n",
    "        [\n",
    "            \n",
    "            gdA.reset_index(drop=True),\n",
    "            gdB_nearest,\n",
    "            pd.Series(dist, name='dist')\n",
    "            \n",
    "        ], \n",
    "        axis=1)\n",
    "\n",
    "    return [gdf, pd.Series(gdB.iloc[idx][\"geometry\"], name =\"geo_wind\")]\n",
    "def me(df_survey, df_env, surv_list):\n",
    "    \n",
    "    df = []\n",
    "    ID = []\n",
    "    for date in surv_list:\n",
    "       \n",
    "        df_envv = df_env[df_env[\"time\"] == date]\n",
    "        df_sur = df_survey[df_survey['surveydate'] == date]\n",
    "        df_ , idx= ck(df_sur, df_envv)\n",
    "        df.append(df_)\n",
    "        ID.append(idx)\n",
    "\n",
    "        \n",
    "    return [pd.concat(df), ID, df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_mer_w_ = pf.make_geo_frame(df_mer_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through the different dates and places and find the closest wind speed at each Survey point\n",
    "frames, index, df_frame = me(df_mer_w_,gdf_wind, dates_surveys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for i in range(len(df_frame)):\n",
    "    index[i].index = np.arange(0, len(index[i]))\n",
    "    df.append(pd.merge(df_frame[i], index[i], how = \"outer\",on = index[i].index))\n",
    "    \n",
    "df_wind_geo = pd.concat(df)\n",
    "df_wind_geo.index = np.arange(0, len(df_wind_geo))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_wind = df_wind_geo[\"geo_wind\"].x\n",
    "lon_wind = df_wind_geo[\"geo_wind\"].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wind.drop(columns = [\"geometry\", \"surface\", \"step\", \"number\", \"valid_time\"], inplace = True)\n",
    "df_wind_eval = []\n",
    "\n",
    "for i in range(len(lat_wind)):\n",
    "    df = df_wind.query(format(f'latitude == {lat_wind[i]} and longitude == {lon_wind[i]}'))\n",
    "    df.drop(columns = [\"latitude\", \"longitude\"], inplace = True)\n",
    "    df.set_index(\"time\", inplace = True)\n",
    "    df = df.transpose()\n",
    "    df_wind_eval.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wind_eval = pd.concat(df_wind_eval)\n",
    "df_wind_eval = df_wind_eval.add_prefix(\"wind_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wind_eval.index = np.arange(0, len(df_wind_eval))\n",
    "df_mer_w.index = np.arange(0, len(df_mer_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mer_w_extended = pd.concat([df_mer_w, df_wind_eval], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended Chlorophyll data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_chlor = xr.open_mfdataset(\"../Data/Environmental_data/chlorophyll/ESACCI-OC-L3S-CHLOR_A-MERGED-1D_DAILY_4km*.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounds of coordinates for Pacific\n",
    "latbounds = [-24, 4]\n",
    "lonbounds = [100, 160]\n",
    "lats = ds_chlor.variables[\"lat\"][:]\n",
    "lons = ds_chlor.variables[\"lon\"][:]\n",
    "# latitude lower and upper index\n",
    "latli = np.argmin( np.abs( lats - latbounds[0] ).values )\n",
    "latui = np.argmin( np.abs( lats - latbounds[1] ).values ) \n",
    "# longitude lower and upper index\n",
    "lonli = np.argmin( np.abs( lons - lonbounds[0] ).values )\n",
    "lonui = np.argmin( np.abs( lons - lonbounds[1] ).values )  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for the given coordinates\n",
    "ChlorSubset = ds_chlor.variables['chlor_a'][ : , latui:latli , lonli:lonui ] \n",
    "# Dataset with the chlor amongst the different coordinates\n",
    "ds_sub_chlor = xr.Dataset(data_vars={\"Chlor\": ChlorSubset}, coords = {\"lon\":ds_chlor[\"lon\"][lonli:lonui], \"lat\": ds_chlor[\"lat\"][latui:latli], \"time\":ds_chlor[\"time\"]})\n",
    "df_chlor = ds_sub_chlor.to_dataframe()\n",
    "\n",
    "df_chlor.reset_index(inplace = True)\n",
    "\n",
    "# remove the Nan values, so that it automatically takes the existing values as closest to the survey points\n",
    "df_chlor = df_chlor.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as intermediate \n",
    "df_chlor.to_csv(\"../Data/Environmental_data/df_chlor.csv\", index = False)\n",
    "\n",
    "df_chlor = pd.read_csv(\"../Data/Environmental_data/df_chlor.csv\")\n",
    "# Change to datetime format\n",
    "df_chlor['time'] = pd.to_datetime(df_chlor['time'], errors='coerce')\n",
    "\n",
    "\n",
    "# Keep only month and year \n",
    "df_chlor[\"time\"] = df_chlor[\"time\"].dt.strftime('%Y-%m')\n",
    "gdf_chlor = gpd.GeoDataFrame(df_chlor, geometry=gpd.points_from_xy(df_chlor.lat, df_chlor.lon))\n",
    "\n",
    "# Merge with the previous frame \n",
    "df_merged_w_ch = dp.merge_(df_mer_w, gdf_chlor, dates_surveys)\n",
    "\n",
    "\n",
    "df_mer_w[\"Chlor\"] = df_merged_w_ch[\"Chlor\"].to_list()\n",
    "df_merged_w_ch = df_mer_w\n",
    "\n",
    "df_merged_w_ch.to_csv(\"../Data/Environmental_data/merged_wind_chlor.csv\", index = False)\n",
    "df_merged_w_ch = pd.read_csv(\"../Data/Environmental_data/merged_wind_chlor.csv\")\n",
    "\n",
    "# Change the \"geometry\" column to geometry type\n",
    "dp.geo_loads(df_merged_w_ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_w_ch = pd.read_csv(\"../Data/Environmental_data/merged_wind_chlor.csv\")\n",
    "\n",
    "# Change the \"geometry\" column to geometry type\n",
    "dp.geo_loads(df_merged_w_ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solar radiation Copernicus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load xarray\n",
    "ds_solar = xr.open_dataset(\"../Data/Environmental_data/solar_rad.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surface net solar radiation, clear sky :: SSRC [J m**-2]\n",
    "# Surface net solar radiation :: SSR [J m**-2]\n",
    "# Make dataframe\n",
    "df_solar = ds_solar.to_dataframe()\n",
    "\n",
    "# Rename and reset longitude and latitude index\n",
    "df_solar.rename(columns = {\"ssr\":\"solar_rad\", \"ssrc\":\"solar_rad_clear_sky\"}, inplace = True)\n",
    "\n",
    "df_solar_indx = df_solar.copy()\n",
    "df_solar.reset_index(inplace = True)\n",
    "\n",
    "df_solar.drop(columns = ['number','time', 'step', 'surface'], inplace = True)\n",
    "\n",
    "\n",
    "# Keep only month and year \n",
    "df_solar[\"valid_time\"] = df_solar[\"valid_time\"].dt.strftime('%Y-%m')\n",
    "\n",
    "gdf_solar = gpd.GeoDataFrame(df_solar, geometry=gpd.points_from_xy(df_solar.latitude, df_solar.longitude))\n",
    "gdf_solar.rename(columns = {\"valid_time\" : \"time\"}, inplace = True)\n",
    "\n",
    "df_merged_w_ch_sol = dp.merge_(df_merged_w_ch, gdf_solar, dates_surveys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solar_indx.reset_index(\"time\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solar_indx[\"time\"] = df_solar_indx[\"time\"].dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_w_ch_sol_ = pf.make_geo_frame(df_merged_w_ch_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through the different dates and places and find the closest wind speed at each Survey point\n",
    "frames, index, df_frame = me(df_merged_w_ch_sol_,gdf_wind, dates_surveys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for i in range(len(df_frame)):\n",
    "    index[i].index = np.arange(0, len(index[i]))\n",
    "    df.append(pd.merge(df_frame[i], index[i], how = \"outer\",on = index[i].index))\n",
    "    \n",
    "df_solar_geo = pd.concat(df)\n",
    "df_solar_geo.index = np.arange(0, len(df_solar_geo))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_solar= df_solar_geo[\"geo_wind\"].x\n",
    "lon_solar = df_solar_geo[\"geo_wind\"].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solar.drop(columns = [\"geometry\"], inplace = True)\n",
    "df_solar_eval = []\n",
    "\n",
    "for i in range(len(lat_wind)):\n",
    "    df = df_solar.query(format(f'latitude == {lat_solar[i]} and longitude == {lon_solar[i]}'))\n",
    "    df.drop(columns = [\"latitude\", \"longitude\"], inplace = True)\n",
    "    df.set_index(\"time\", inplace = True)\n",
    "    df = df.transpose()\n",
    "    df_solar_eval.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solar_eval = pd.concat(df_solar_eval)\n",
    "df_solar_eval = df_solar_eval.add_prefix(\"solar_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_w_ch[\"solar_rad\"] = df_merged_w_ch_sol[\"solar_rad\"].to_list()\n",
    "df_merged_w_ch[\"solar_rad_clear_sky\"] = df_merged_w_ch_sol[\"solar_rad_clear_sky\"].to_list()\n",
    "df_merged_w_ch_sol = df_merged_w_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_w_ch_sol.to_csv(\"../Data/Environmental_data/merged_wind_chlor_sol.csv\", index = False)\n",
    "df_merged_w_ch_sol = pd.read_csv(\"../Data/Environmental_data/merged_wind_chlor_sol.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solar_rad = df_solar_eval.loc[\"solar_rad\"]\n",
    "df_solar_rad_clear = df_solar_eval.loc[\"solar_rad_clear_sky\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solar_rad_clear = df_solar_rad_clear.add_prefix(\"clear_rad_\")\n",
    "df_solar_rad = df_solar_rad.add_prefix(\"rad_\")\n",
    "df_solar_rad_clear.index = np.arange(0, len(df_solar_rad_clear))\n",
    "df_solar_rad.index = np.arange(0, len(df_solar_rad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended = pd.concat([df_mer_w_extended, df_solar_rad, df_solar_rad_clear], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ocean depth Copernicus // Sentinel 3\n",
    "\n",
    "Ocean level, so negative numbers are for below water :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load xarray for depth\n",
    "ds_depth = xr.open_dataset(\"../Data/Environmental_data/depth/depth.nc\")\n",
    "\n",
    "# Set latitude and longitude as index\n",
    "df_merged_w_ch_sol_ind = df_merged_w_ch_sol.set_index([\"lat_start\", \"lng_start\"])\n",
    "\n",
    "# Make a NetCDF with the multi-index dataframe \n",
    "xr_merged = xr.Dataset.from_dataframe(df_merged_w_ch_sol_ind)\n",
    "xr_merged = xr_merged.rename({\"lat_start\" : \"lat\"})\n",
    "xr_merged= xr_merged.rename({\"lng_start\" : \"lon\"})\n",
    "\n",
    "\n",
    "# Keep interesting lat/long\n",
    "long_ = [xr_merged[\"lon\"].values]\n",
    "latg_ = [xr_merged[\"lat\"].values]\n",
    "\n",
    "# Find nearest depth to the given lat/lon\n",
    "df_depth_near = ds_depth.sel(lon=long_[0], lat=latg_[0], method='nearest')\n",
    "\n",
    "# Assign the coordinates of interst as coordinates in NetCdf\n",
    "depth_same_coord = df_depth_near.assign_coords(lon = long_[0], lat = latg_[0])\n",
    "xr_merged_depth = xr_merged.merge(depth_same_coord, join = \"inner\")\n",
    "\n",
    "df_depth_merged = xr_merged_depth.to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nan values for unknown depths and reset index (lat,lon)\n",
    "df_merged = df_depth_merged.dropna().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree Heating Week "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treat_SST_DHW(df, gdf):\n",
    "    df[\"id\"] = df[\"id\"].str.replace('R', \"\").astype(int)\n",
    "    \n",
    "    df = df.merge(gdf[[\"id\", \"geometry\"]], how='left')\n",
    "    df.dropna(inplace = True)\n",
    "    \n",
    "    df_temp = df.drop(columns = [\"id\", \"geometry\"])\n",
    "    df_temp.columns = pd.to_datetime(df_temp.columns)\n",
    "    df_temp.columns = df_temp.columns.strftime(\"%Y-%m\")\n",
    "    df_temp.insert(0, \"id\", df[\"id\"])\n",
    "    df_temp.insert(0, \"geometry\", df[\"geometry\"])\n",
    "    df = df_temp.copy()\n",
    "    df = pf.make_geo_frame(df)\n",
    "    return df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "DHW_IDN = pd.read_csv(\"../Data/Environmental_data/DHW/DHW_Indonesia.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DHW_IDN.head()\n",
    "DHW_IDN = treat_SST_DHW(DHW_IDN, gdf_IND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-011370f50624>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mDHW_IDN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Data/Environmental_data/DHW/DHW_Indonesia.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mDHW_IDN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreat_SST_DHW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDHW_IDN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdf_IND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeo_loads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_merged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mSST_IDN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Data/Environmental_data/SST/SST_Indonesia.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mSST_IDN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreat_SST_DHW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSST_IDN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdf_IND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_merged' is not defined"
     ]
    }
   ],
   "source": [
    "# Degree Heating week and SST for Indonesia\n",
    "\n",
    "DHW_IDN = pd.read_csv(\"../Data/Environmental_data/DHW/DHW_Indonesia.csv\")\n",
    "DHW_IDN = treat_SST_DHW(DHW_IDN, gdf_IND)\n",
    "dp.geo_loads(df_merged)\n",
    "SST_IDN = pd.read_csv(\"../Data/Environmental_data/SST/SST_Indonesia.csv\")\n",
    "SST_IDN = treat_SST_DHW(SST_IDN, gdf_IND)\n",
    "df_merged = pf.make_geo_frame(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_swap = df_merged.copy()\n",
    "# Swap the coordinates \n",
    "df_swap[\"geometry\"] = df_swap.geometry.map(lambda polygon: shapely.ops.transform(lambda x, y: (y, x), polygon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DHW merged:  (0, 447)\n",
      "SST merged:  (0, 447)\n"
     ]
    }
   ],
   "source": [
    "# Take the intersection\n",
    "# nothing in common...\n",
    "DHW_merged_IDN = gpd.sjoin(DHW_IDN, df_swap[df_swap[\"country\"] == \"IDN\"], how=\"inner\", op='intersects')\n",
    "print(\"DHW merged: \", DHW_merged_IDN.shape)\n",
    "SST_merged_IDN = gpd.sjoin(SST_IDN, df_swap[df_swap[\"country\"] == \"IDN\"], how=\"inner\", op='intersects')\n",
    "print(\"SST merged: \", SST_merged_IDN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us use another strategy. I will take the centroid of the polygon and estimate the closests neighbor\n",
    "DHW_IDN.geometry = DHW_IDN['geometry'].centroid\n",
    "df_near_merge_IDN_DHW = dp.ckdnearest(df_swap[df_swap[\"country\"] == \"IDN\"], DHW_IDN).drop(columns = \"dist\")\n",
    "\n",
    "SST_IDN.geometry = SST_IDN['geometry'].centroid\n",
    "df_near_merge_IDN_SST = dp.ckdnearest(df_swap[df_swap[\"country\"] == \"IDN\"], SST_IDN).drop(columns = \"dist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for both SST and DHW\n",
    "dates_to_drop = df_near_merge_IDN_DHW.columns[17:][df_near_merge_IDN_DHW.columns[17:].isin(df_near_merge_IDN_DHW[\"surveydate\"]) == False]\n",
    "dates_to_keep = df_near_merge_IDN_DHW.columns[17:][df_near_merge_IDN_DHW.columns[17:].isin(df_near_merge_IDN_DHW[\"surveydate\"])]\n",
    "df_near_merge_IDN_SST.drop(columns = dates_to_drop,  inplace = True)\n",
    "df_near_merge_IDN_DHW.drop(columns = dates_to_drop,  inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_near_merge_IDN_DHW['DHW'] = df_near_merge_IDN_DHW.lookup(df_near_merge_IDN_DHW.index, df_near_merge_IDN_DHW['surveydate'].astype(str))\n",
    "df_near_merge_IDN_DHW.drop(columns = dates_to_keep,  inplace = True)\n",
    "df_near_merge_IDN_SST['SST'] = df_near_merge_IDN_SST.lookup(df_near_merge_IDN_SST.index, df_near_merge_IDN_SST['surveydate'].astype(str))\n",
    "df_near_merge_IDN_SST.drop(columns = dates_to_keep,  inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_near_merge_IDN = df_near_merge_IDN_DHW.copy()\n",
    "df_near_merge_IDN[\"SST\"] = df_near_merge_IDN_SST['SST']\n",
    "\n",
    "# Indonesia done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for Timor Leste\n",
    "# Degree Heating week and SST\n",
    "DHW_TLS = pd.read_csv(\"../Data/Environmental_data/DHW/DHW_Timor.csv\")\n",
    "DHW_TLS = treat_SST_DHW(DHW_TLS, gdf_TLS)\n",
    "SST_TLS = pd.read_csv(\"../Data/Environmental_data/SST/SST_Timor.csv\")\n",
    "SST_TLS = treat_SST_DHW(SST_TLS, gdf_TLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DHW merged:  (0, 447)\n",
      "SST merged:  (0, 447)\n"
     ]
    }
   ],
   "source": [
    "#  Nothing in common\n",
    "DHW_merged_TLS = gpd.sjoin(DHW_TLS, df_swap[df_swap[\"country\"] == \"TLS\"], how=\"inner\", op='intersects')\n",
    "print(\"DHW merged: \", DHW_merged_TLS.shape)\n",
    "SST_merged_TLS = gpd.sjoin(SST_TLS, df_swap[df_swap[\"country\"] == \"TLS\"], how=\"inner\", op='intersects')\n",
    "print(\"SST merged: \", SST_merged_TLS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same centroid strategy\n",
    "DHW_TLS.geometry = DHW_TLS['geometry'].centroid\n",
    "df_near_merge_TLS_DHW = dp.ckdnearest(df_swap[df_swap[\"country\"] == \"TLS\"], DHW_TLS)\n",
    "\n",
    "SST_TLS.geometry = SST_TLS['geometry'].centroid\n",
    "df_near_merge_TLS_SST = dp.ckdnearest(df_swap[df_swap[\"country\"] == \"TLS\"], SST_TLS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for both SST and DHW\n",
    "dates_to_drop = df_near_merge_TLS_DHW.columns[17:][df_near_merge_TLS_DHW.columns[17:].isin(df_near_merge_TLS_DHW[\"surveydate\"]) == False]\n",
    "dates_to_keep = df_near_merge_TLS_DHW.columns[17:][df_near_merge_TLS_DHW.columns[17:].isin(df_near_merge_TLS_DHW[\"surveydate\"])]\n",
    "df_near_merge_TLS_SST.drop(columns = dates_to_drop,  inplace = True)\n",
    "df_near_merge_TLS_DHW.drop(columns = dates_to_drop,  inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>transectid</th>\n",
       "      <th>surveydate</th>\n",
       "      <th>pr_hard_coral</th>\n",
       "      <th>pr_algae</th>\n",
       "      <th>pr_soft_coral</th>\n",
       "      <th>pr_oth_invert</th>\n",
       "      <th>pr_other</th>\n",
       "      <th>country</th>\n",
       "      <th>geometry</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>Chlor</th>\n",
       "      <th>solar_rad</th>\n",
       "      <th>solar_rad_clear_sky</th>\n",
       "      <th>elevation</th>\n",
       "      <th>id</th>\n",
       "      <th>DHW</th>\n",
       "      <th>SST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.186476</td>\n",
       "      <td>124.391635</td>\n",
       "      <td>30023.0</td>\n",
       "      <td>2014-07</td>\n",
       "      <td>0.2536</td>\n",
       "      <td>0.3902</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.2063</td>\n",
       "      <td>TLS</td>\n",
       "      <td>POINT (124.39163 -9.18648)</td>\n",
       "      <td>3.709066</td>\n",
       "      <td>0.406888</td>\n",
       "      <td>16667136.0</td>\n",
       "      <td>18682368.0</td>\n",
       "      <td>-85</td>\n",
       "      <td>17651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.668065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.173817</td>\n",
       "      <td>124.409284</td>\n",
       "      <td>30022.0</td>\n",
       "      <td>2014-07</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.3139</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>TLS</td>\n",
       "      <td>POINT (124.40928 -9.17382)</td>\n",
       "      <td>3.709066</td>\n",
       "      <td>0.406888</td>\n",
       "      <td>16667136.0</td>\n",
       "      <td>18682368.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>17651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.668065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lat         lon  transectid surveydate  pr_hard_coral  pr_algae  \\\n",
       "0 -9.186476  124.391635     30023.0    2014-07         0.2536    0.3902   \n",
       "1 -9.173817  124.409284     30022.0    2014-07         0.1146    0.3139   \n",
       "\n",
       "   pr_soft_coral  pr_oth_invert  pr_other country                    geometry  \\\n",
       "0         0.1027         0.0472    0.2063     TLS  POINT (124.39163 -9.18648)   \n",
       "1         0.0755         0.0350    0.4609     TLS  POINT (124.40928 -9.17382)   \n",
       "\n",
       "   wind_speed     Chlor   solar_rad  solar_rad_clear_sky  elevation     id  \\\n",
       "0    3.709066  0.406888  16667136.0           18682368.0        -85  17651   \n",
       "1    3.709066  0.406888  16667136.0           18682368.0        -15  17651   \n",
       "\n",
       "   DHW        SST  \n",
       "0  0.0  27.668065  \n",
       "1  0.0  27.668065  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_near_merge_TLS_DHW['DHW'] = df_near_merge_TLS_DHW.lookup(df_near_merge_TLS_DHW.index, df_near_merge_TLS_DHW['surveydate'].astype(str))\n",
    "df_near_merge_TLS_DHW.drop(columns = dates_to_keep,  inplace = True)\n",
    "df_near_merge_TLS_SST['SST'] = df_near_merge_TLS_SST.lookup(df_near_merge_TLS_SST.index, df_near_merge_TLS_SST['surveydate'].astype(str))\n",
    "df_near_merge_TLS_SST.drop(columns = dates_to_keep,  inplace = True)\n",
    "df_near_merge_TLS = df_near_merge_TLS_DHW.copy()\n",
    "df_near_merge_TLS[\"SST\"] = df_near_merge_TLS_SST['SST']\n",
    "df_near_merge_TLS.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solomon\n",
    "# Degree Heating week and SST\n",
    "DHW_SLB = pd.read_csv(\"../Data/Environmental_data/DHW/DHW_Indonesia.csv\")\n",
    "DHW_SLB = treat_SST_DHW(DHW_SLB, gdf_SLB)\n",
    "SST_SLB = pd.read_csv(\"../Data/Environmental_data/SST/SST_Solomon.csv\")\n",
    "SST_SLB = treat_SST_DHW(SST_SLB, gdf_SLB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DHW merged:  (0, 447)\n",
      "SST merged:  (11, 447)\n"
     ]
    }
   ],
   "source": [
    "# Nothing in common for DHW and 11 for SST\n",
    "DHW_merged_SLB = gpd.sjoin(DHW_SLB, df_swap[df_swap[\"country\"] == \"SLB\"], how=\"inner\", op='intersects')\n",
    "print(\"DHW merged: \", DHW_merged_SLB.shape)\n",
    "SST_merged_SLB = gpd.sjoin(SST_SLB, df_swap[df_swap[\"country\"] == \"SLB\"], how=\"inner\", op='intersects')\n",
    "print(\"SST merged: \", SST_merged_SLB.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same\n",
    "DHW_SLB.geometry = DHW_SLB['geometry'].centroid\n",
    "df_near_merge_SLB_DHW = dp.ckdnearest(df_swap[df_swap[\"country\"] == \"SLB\"], DHW_SLB)\n",
    "SST_SLB.geometry = SST_SLB['geometry'].centroid\n",
    "df_near_merge_SLB_SST = dp.ckdnearest(df_swap[df_swap[\"country\"] == \"SLB\"], SST_SLB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for both SST and DHW\n",
    "dates_to_drop = df_near_merge_SLB_DHW.columns[17:][df_near_merge_SLB_DHW.columns[17:].isin(df_near_merge_SLB_DHW[\"surveydate\"]) == False]\n",
    "dates_to_keep = df_near_merge_SLB_DHW.columns[17:][df_near_merge_SLB_DHW.columns[17:].isin(df_near_merge_SLB_DHW[\"surveydate\"])]\n",
    "df_near_merge_SLB_SST.drop(columns = dates_to_drop,  inplace = True)\n",
    "df_near_merge_SLB_DHW.drop(columns = dates_to_drop,  inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>transectid</th>\n",
       "      <th>surveydate</th>\n",
       "      <th>pr_hard_coral</th>\n",
       "      <th>pr_algae</th>\n",
       "      <th>pr_soft_coral</th>\n",
       "      <th>pr_oth_invert</th>\n",
       "      <th>pr_other</th>\n",
       "      <th>country</th>\n",
       "      <th>geometry</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>Chlor</th>\n",
       "      <th>solar_rad</th>\n",
       "      <th>solar_rad_clear_sky</th>\n",
       "      <th>elevation</th>\n",
       "      <th>id</th>\n",
       "      <th>DHW</th>\n",
       "      <th>SST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.701401</td>\n",
       "      <td>157.815640</td>\n",
       "      <td>34016.0</td>\n",
       "      <td>2014-11</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.8454</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>SLB</td>\n",
       "      <td>POINT (157.81564 -8.70140)</td>\n",
       "      <td>4.663486</td>\n",
       "      <td>0.170505</td>\n",
       "      <td>19759616.0</td>\n",
       "      <td>26144256.0</td>\n",
       "      <td>-46</td>\n",
       "      <td>16975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.676629</td>\n",
       "      <td>157.839278</td>\n",
       "      <td>34015.0</td>\n",
       "      <td>2014-11</td>\n",
       "      <td>0.1362</td>\n",
       "      <td>0.6395</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.1865</td>\n",
       "      <td>SLB</td>\n",
       "      <td>POINT (157.83928 -8.67663)</td>\n",
       "      <td>4.663486</td>\n",
       "      <td>0.170505</td>\n",
       "      <td>19759616.0</td>\n",
       "      <td>26144256.0</td>\n",
       "      <td>-5</td>\n",
       "      <td>16975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lat         lon  transectid surveydate  pr_hard_coral  pr_algae  \\\n",
       "0 -8.701401  157.815640     34016.0    2014-11         0.1154    0.8454   \n",
       "1 -8.676629  157.839278     34015.0    2014-11         0.1362    0.6395   \n",
       "\n",
       "   pr_soft_coral  pr_oth_invert  pr_other country                    geometry  \\\n",
       "0         0.0167         0.0147    0.0075     SLB  POINT (157.81564 -8.70140)   \n",
       "1         0.0342         0.0037    0.1865     SLB  POINT (157.83928 -8.67663)   \n",
       "\n",
       "   wind_speed     Chlor   solar_rad  solar_rad_clear_sky  elevation     id  \\\n",
       "0    4.663486  0.170505  19759616.0           26144256.0        -46  16975   \n",
       "1    4.663486  0.170505  19759616.0           26144256.0         -5  16975   \n",
       "\n",
       "   DHW     SST  \n",
       "0  0.0  29.344  \n",
       "1  0.0  29.421  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_near_merge_SLB_DHW['DHW'] = df_near_merge_SLB_DHW.lookup(df_near_merge_SLB_DHW.index, df_near_merge_SLB_DHW['surveydate'].astype(str))\n",
    "df_near_merge_SLB_DHW.drop(columns = dates_to_keep,  inplace = True)\n",
    "df_near_merge_SLB_SST['SST'] = df_near_merge_SLB_SST.lookup(df_near_merge_SLB_SST.index, df_near_merge_SLB_SST['surveydate'].astype(str))\n",
    "df_near_merge_SLB_SST.drop(columns = dates_to_keep,  inplace = True)\n",
    "df_near_merge_SLB = df_near_merge_SLB_DHW.copy()\n",
    "df_near_merge_SLB[\"SST\"] = df_near_merge_SLB_SST['SST']\n",
    "df_near_merge_SLB.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great Barrier Reef\n",
    "\n",
    "# Degree Heating week and SST\n",
    "DHW_GBR = pd.read_csv(\"../Data/Environmental_data/DHW/DHW_GBR.csv\")\n",
    "gdf_AUS[\"id\"] = gdf_AUS[\"id\"].str.replace('R', \"\").astype(int)\n",
    "DHW_GBR = treat_SST_DHW(DHW_GBR, gdf_AUS)\n",
    "SST_GBR = pd.read_csv(\"../Data/Environmental_data/SST/SST_GBR.csv\")\n",
    "SST_GBR = treat_SST_DHW(SST_GBR, gdf_AUS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For GBR_DHW:  (206, 447)  in common\n",
      "For GBR_SST:  (206, 447)  in common\n"
     ]
    }
   ],
   "source": [
    "# 206 / 260 are merged within for the rest let us take the closest point\n",
    "DHW_merged_GBR = gpd.sjoin(df_swap[df_swap[\"country\"] == \"AUS\"],DHW_GBR,  how=\"inner\", op='intersects')\n",
    "SST_merged_GBR = gpd.sjoin(df_swap[df_swap[\"country\"] == \"AUS\"],SST_GBR, how=\"inner\", op='intersects')\n",
    "print(\"For GBR_DHW: \", DHW_merged_GBR.shape, \" in common\")\n",
    "print(\"For GBR_SST: \", SST_merged_GBR.shape, \" in common\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_DHW = DHW_merged_GBR[DHW_merged_GBR.columns[:16]]\n",
    "temp_SST = SST_merged_GBR[SST_merged_GBR.columns[:16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff_neig_DHW = pd.concat([temp_DHW,df_swap[df_swap[\"country\"] == \"AUS\"]]).drop_duplicates(keep=False)\n",
    "df_diff_neig_SST = pd.concat([temp_SST,df_swap[df_swap[\"country\"] == \"AUS\"]]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us use anothgeometrystrategy. I will take the centroid of the polygon and estimate the closests neighbor\n",
    "DHW_GBR.geometry = DHW_GBR['geometry'].centroid\n",
    "df_near_DHW = dp.ckdnearest(df_diff_neig_DHW,DHW_GBR)\n",
    "\n",
    "# Let us use another strategy. I will take the centroid of the polygon and estimate the closests neighbor\n",
    "SST_GBR.geometry = SST_GBR['geometry'].centroid\n",
    "df_near_SST = dp.ckdnearest(df_diff_neig_SST,SST_GBR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "DHW_GBR_year = df_near_DHW.append(DHW_merged_GBR).drop(columns = \"dist\")\n",
    "SST_GBR_year = df_near_SST.append(SST_merged_GBR).drop(columns = \"dist\")\n",
    "SST_GBR_year.index = np.arange(260)\n",
    "DHW_GBR_year.index = np.arange(260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for both SST and DHW\n",
    "dates_to_drop = DHW_GBR_year.columns[17:][DHW_GBR_year.columns[17:].isin(DHW_GBR_year[\"surveydate\"]) == False]\n",
    "dates_to_keep = DHW_GBR_year.columns[17:][DHW_GBR_year.columns[17:].isin(DHW_GBR_year[\"surveydate\"])]\n",
    "SST_GBR_year.drop(columns = dates_to_drop,  inplace = True)\n",
    "DHW_GBR_year.drop(columns = dates_to_drop,  inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>transectid</th>\n",
       "      <th>surveydate</th>\n",
       "      <th>pr_hard_coral</th>\n",
       "      <th>pr_algae</th>\n",
       "      <th>pr_soft_coral</th>\n",
       "      <th>pr_oth_invert</th>\n",
       "      <th>pr_other</th>\n",
       "      <th>country</th>\n",
       "      <th>geometry</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>Chlor</th>\n",
       "      <th>solar_rad</th>\n",
       "      <th>solar_rad_clear_sky</th>\n",
       "      <th>elevation</th>\n",
       "      <th>id</th>\n",
       "      <th>DHW</th>\n",
       "      <th>SST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-18.833291</td>\n",
       "      <td>147.651632</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>2012-10</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>0.6852</td>\n",
       "      <td>0.0978</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>AUS</td>\n",
       "      <td>POINT (147.65163 -18.83329)</td>\n",
       "      <td>6.969212</td>\n",
       "      <td>0.155895</td>\n",
       "      <td>23342080.0</td>\n",
       "      <td>26556928.0</td>\n",
       "      <td>-34</td>\n",
       "      <td>41573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.307097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-17.698393</td>\n",
       "      <td>148.513366</td>\n",
       "      <td>10013.0</td>\n",
       "      <td>2012-09</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.5873</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.2874</td>\n",
       "      <td>AUS</td>\n",
       "      <td>POINT (148.51337 -17.69839)</td>\n",
       "      <td>6.625403</td>\n",
       "      <td>0.174489</td>\n",
       "      <td>21595512.0</td>\n",
       "      <td>23705776.0</td>\n",
       "      <td>-18</td>\n",
       "      <td>47314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.838333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat         lon  transectid surveydate  pr_hard_coral  pr_algae  \\\n",
       "0 -18.833291  147.651632     11002.0    2012-10         0.1586    0.6852   \n",
       "1 -17.698393  148.513366     10013.0    2012-09         0.0986    0.5873   \n",
       "\n",
       "   pr_soft_coral  pr_oth_invert  pr_other country  \\\n",
       "0         0.0978         0.0216    0.0366     AUS   \n",
       "1         0.0167         0.0099    0.2874     AUS   \n",
       "\n",
       "                      geometry  wind_speed     Chlor   solar_rad  \\\n",
       "0  POINT (147.65163 -18.83329)    6.969212  0.155895  23342080.0   \n",
       "1  POINT (148.51337 -17.69839)    6.625403  0.174489  21595512.0   \n",
       "\n",
       "   solar_rad_clear_sky  elevation     id  DHW        SST  \n",
       "0           26556928.0        -34  41573  0.0  25.307097  \n",
       "1           23705776.0        -18  47314  0.0  24.838333  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DHW_GBR_year['DHW'] = DHW_GBR_year.lookup(DHW_GBR_year.index, DHW_GBR_year['surveydate'].astype(str))\n",
    "DHW_GBR_year.drop(columns = dates_to_keep,  inplace = True)\n",
    "SST_GBR_year['SST'] = SST_GBR_year.lookup(SST_GBR_year.index, SST_GBR_year['surveydate'].astype(str))\n",
    "SST_GBR_year.drop(columns = dates_to_keep,  inplace = True)\n",
    "df_near_merge_GBR = DHW_GBR_year.copy()\n",
    "df_near_merge_GBR[\"SST\"] = SST_GBR_year['SST']\n",
    "df_near_merge_GBR.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape  (416, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>transectid</th>\n",
       "      <th>surveydate</th>\n",
       "      <th>pr_hard_coral</th>\n",
       "      <th>pr_algae</th>\n",
       "      <th>pr_soft_coral</th>\n",
       "      <th>pr_oth_invert</th>\n",
       "      <th>pr_other</th>\n",
       "      <th>country</th>\n",
       "      <th>geometry</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>Chlor</th>\n",
       "      <th>solar_rad</th>\n",
       "      <th>solar_rad_clear_sky</th>\n",
       "      <th>elevation</th>\n",
       "      <th>id</th>\n",
       "      <th>DHW</th>\n",
       "      <th>SST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-18.833291</td>\n",
       "      <td>147.651632</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>2012-10</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>0.6852</td>\n",
       "      <td>0.0978</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>AUS</td>\n",
       "      <td>POINT (147.65163 -18.83329)</td>\n",
       "      <td>6.969212</td>\n",
       "      <td>0.155895</td>\n",
       "      <td>23342080.0</td>\n",
       "      <td>26556928.0</td>\n",
       "      <td>-34</td>\n",
       "      <td>41573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.307097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-17.698393</td>\n",
       "      <td>148.513366</td>\n",
       "      <td>10013.0</td>\n",
       "      <td>2012-09</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.5873</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.2874</td>\n",
       "      <td>AUS</td>\n",
       "      <td>POINT (148.51337 -17.69839)</td>\n",
       "      <td>6.625403</td>\n",
       "      <td>0.174489</td>\n",
       "      <td>21595512.0</td>\n",
       "      <td>23705776.0</td>\n",
       "      <td>-18</td>\n",
       "      <td>47314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.838333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-16.175264</td>\n",
       "      <td>145.891157</td>\n",
       "      <td>10003.0</td>\n",
       "      <td>2017-10</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.5264</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.2968</td>\n",
       "      <td>AUS</td>\n",
       "      <td>POINT (145.89116 -16.17526)</td>\n",
       "      <td>6.687017</td>\n",
       "      <td>0.297231</td>\n",
       "      <td>21459968.0</td>\n",
       "      <td>26170368.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>29655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.130000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat         lon  transectid surveydate  pr_hard_coral  pr_algae  \\\n",
       "0 -18.833291  147.651632     11002.0    2012-10         0.1586    0.6852   \n",
       "1 -17.698393  148.513366     10013.0    2012-09         0.0986    0.5873   \n",
       "2 -16.175264  145.891157     10003.0    2017-10         0.1385    0.5264   \n",
       "\n",
       "   pr_soft_coral  pr_oth_invert  pr_other country  \\\n",
       "0         0.0978         0.0216    0.0366     AUS   \n",
       "1         0.0167         0.0099    0.2874     AUS   \n",
       "2         0.0324         0.0058    0.2968     AUS   \n",
       "\n",
       "                      geometry  wind_speed     Chlor   solar_rad  \\\n",
       "0  POINT (147.65163 -18.83329)    6.969212  0.155895  23342080.0   \n",
       "1  POINT (148.51337 -17.69839)    6.625403  0.174489  21595512.0   \n",
       "2  POINT (145.89116 -16.17526)    6.687017  0.297231  21459968.0   \n",
       "\n",
       "   solar_rad_clear_sky  elevation     id  DHW        SST  \n",
       "0           26556928.0        -34  41573  0.0  25.307097  \n",
       "1           23705776.0        -18  47314  0.0  24.838333  \n",
       "2           26170368.0         -2  29655  0.0  26.130000  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now combine all of them \n",
    "# df_near_merge_GBR, df_near_merge_SLB, df_near_merge_IDN, df_near_merge_TLS\n",
    "\n",
    "df_Survey_merged = pd.concat([df_near_merge_GBR,df_near_merge_SLB, df_near_merge_IDN, df_near_merge_TLS]).drop_duplicates(keep=False)\n",
    "print(\"Shape \",df_Survey_merged.shape)\n",
    "df_Survey_merged.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Survey_merged.to_csv(\"../Data/Environmental_data/merged_before_port.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_Survey_merged = pd.read_csv(\"../Data/Environmental_data/merged_before_port.csv\")\n",
    "\n",
    "dp.geo_loads(df_Survey_merged)\n",
    "df_Survey_merged = pf.make_geo_frame(df_Survey_merged)\n",
    "\n",
    "\n",
    "\n",
    "df_Survey_merged[\"geometry\"] = df_Survey_merged.geometry.map(lambda polygon: shapely.ops.transform(lambda x, y: (y, x), polygon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SST extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "DHW_all = pd.concat([DHW_SLB, DHW_GBR, DHW_TLS, DHW_SLB], axis = 0)\n",
    "SST_all = pd.concat([SST_SLB, SST_GBR, SST_TLS, SST_SLB], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swap done\n"
     ]
    }
   ],
   "source": [
    "dp.swap_coordinates(DHW_all)\n",
    "dp.swap_coordinates(SST_all)\n",
    "print(\"Swap done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "DHW_all[\"latitude\"] = DHW_all[\"geometry\"].x\n",
    "DHW_all[\"longitude\"] = DHW_all[\"geometry\"].y\n",
    "SST_all[\"latitude\"] = SST_all[\"geometry\"].x\n",
    "SST_all[\"longitude\"] = SST_all[\"geometry\"].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frame_SST, index_SST = ck(df_extended, SST_all)\n",
    "index_SST.index = np.arange(0, len(index_SST))\n",
    "\n",
    "df_SST_geo = df_extended.merge(index_SST, how = \"outer\", on = index_SST.index)\n",
    "df_SST_geo = pf.make_geo_frame(df_SST_geo)\n",
    "lat_SST= df_SST_geo[\"geo_wind\"].x\n",
    "lon_SST = df_SST_geo[\"geo_wind\"].y\n",
    "SST_all.drop(columns = [\"geometry\", \"id\"], inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "df_SST_eval = []\n",
    "\n",
    "for i in range(len(lat_SST)):\n",
    "    df = SST_all.query(format(f'latitude == {lat_SST[i]} and longitude == {lon_SST[i]}'))\n",
    "    \n",
    "    df.drop(columns = [\"latitude\", \"longitude\"], inplace = True)\n",
    "    \n",
    "    df.drop_duplicates(keep = \"first\", inplace = True)\n",
    "    \n",
    "    \n",
    "\n",
    "    df_SST_eval.append(df)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SST_eval = pd.concat(df_SST_eval)\n",
    "\n",
    "df_SST_eval = df_SST_eval.add_prefix(\"SST_\")\n",
    "df_SST_eval.index = np.arange(0, len(df_SST_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frame_DHW, index_DHW = ck(df_extended, DHW_all)\n",
    "index_DHW.index = np.arange(0, len(index_DHW))\n",
    "df_DHW_geo = df_extended.merge(index_DHW, how = \"outer\", on = index_DHW.index)\n",
    "df_DHW_geo = pf.make_geo_frame(df_DHW_geo)\n",
    "\n",
    "lat_DHW= df_DHW_geo[\"geo_wind\"].x\n",
    "lon_DHW = df_DHW_geo[\"geo_wind\"].y\n",
    "\n",
    "\n",
    "DHW_all.drop(columns = [\"geometry\", \"id\"], inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "df_DHW_eval = []\n",
    "\n",
    "for i in range(len(lat_DHW)):\n",
    "    df = DHW_all.query(format(f'latitude == {lat_DHW[i]} and longitude == {lon_DHW[i]}'))\n",
    "    \n",
    "    df.drop(columns = [\"latitude\", \"longitude\"], inplace = True)\n",
    "    \n",
    "    df.drop_duplicates(keep = \"first\", inplace = True)\n",
    "    \n",
    "\n",
    "    df_DHW_eval.append(df)\n",
    "df_DHW_eval = pd.concat(df_DHW_eval)\n",
    "\n",
    "df_DHW_eval = df_DHW_eval.add_prefix(\"DHW_\")\n",
    "df_DHW_eval.index = np.arange(0, len(df_DHW_eval))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended = pd.concat([df_extended, df_DHW_eval, df_SST_eval], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transectid</th>\n",
       "      <th>surveydate</th>\n",
       "      <th>pr_hard_coral</th>\n",
       "      <th>pr_algae</th>\n",
       "      <th>pr_soft_coral</th>\n",
       "      <th>pr_oth_invert</th>\n",
       "      <th>pr_other</th>\n",
       "      <th>country</th>\n",
       "      <th>lat_start</th>\n",
       "      <th>lng_start</th>\n",
       "      <th>...</th>\n",
       "      <th>SST_2020-03</th>\n",
       "      <th>SST_2020-04</th>\n",
       "      <th>SST_2020-05</th>\n",
       "      <th>SST_2020-06</th>\n",
       "      <th>SST_2020-07</th>\n",
       "      <th>SST_2020-08</th>\n",
       "      <th>SST_2020-09</th>\n",
       "      <th>SST_2020-10</th>\n",
       "      <th>SST_2020-11</th>\n",
       "      <th>SST_2020-12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>2012-09</td>\n",
       "      <td>0.1856</td>\n",
       "      <td>0.3724</td>\n",
       "      <td>0.2710</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>AUS</td>\n",
       "      <td>-16.189023</td>\n",
       "      <td>145.898104</td>\n",
       "      <td>...</td>\n",
       "      <td>29.131290</td>\n",
       "      <td>28.149000</td>\n",
       "      <td>26.596774</td>\n",
       "      <td>25.201333</td>\n",
       "      <td>25.066452</td>\n",
       "      <td>24.992258</td>\n",
       "      <td>25.365333</td>\n",
       "      <td>26.007742</td>\n",
       "      <td>27.440667</td>\n",
       "      <td>28.819677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>2012-09</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.3079</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>AUS</td>\n",
       "      <td>-16.189303</td>\n",
       "      <td>145.898254</td>\n",
       "      <td>...</td>\n",
       "      <td>29.131290</td>\n",
       "      <td>28.149000</td>\n",
       "      <td>26.596774</td>\n",
       "      <td>25.201333</td>\n",
       "      <td>25.066452</td>\n",
       "      <td>24.992258</td>\n",
       "      <td>25.365333</td>\n",
       "      <td>26.007742</td>\n",
       "      <td>27.440667</td>\n",
       "      <td>28.819677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>2012-09</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>0.5653</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0917</td>\n",
       "      <td>AUS</td>\n",
       "      <td>-16.175768</td>\n",
       "      <td>145.891676</td>\n",
       "      <td>...</td>\n",
       "      <td>29.131290</td>\n",
       "      <td>28.149000</td>\n",
       "      <td>26.596774</td>\n",
       "      <td>25.201333</td>\n",
       "      <td>25.066452</td>\n",
       "      <td>24.992258</td>\n",
       "      <td>25.365333</td>\n",
       "      <td>26.007742</td>\n",
       "      <td>27.440667</td>\n",
       "      <td>28.819677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004</td>\n",
       "      <td>2012-09</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>0.5706</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.2748</td>\n",
       "      <td>AUS</td>\n",
       "      <td>-16.536645</td>\n",
       "      <td>147.806796</td>\n",
       "      <td>...</td>\n",
       "      <td>29.189032</td>\n",
       "      <td>28.035333</td>\n",
       "      <td>26.689355</td>\n",
       "      <td>25.959667</td>\n",
       "      <td>25.159355</td>\n",
       "      <td>25.284839</td>\n",
       "      <td>25.236000</td>\n",
       "      <td>25.908065</td>\n",
       "      <td>27.396333</td>\n",
       "      <td>28.501613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10005</td>\n",
       "      <td>2012-09</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.7894</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>AUS</td>\n",
       "      <td>-16.529216</td>\n",
       "      <td>147.802582</td>\n",
       "      <td>...</td>\n",
       "      <td>29.189032</td>\n",
       "      <td>28.035333</td>\n",
       "      <td>26.689355</td>\n",
       "      <td>25.959667</td>\n",
       "      <td>25.159355</td>\n",
       "      <td>25.284839</td>\n",
       "      <td>25.236000</td>\n",
       "      <td>25.908065</td>\n",
       "      <td>27.396333</td>\n",
       "      <td>28.501613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>32022</td>\n",
       "      <td>2018-06</td>\n",
       "      <td>0.0664</td>\n",
       "      <td>0.7374</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>IDN</td>\n",
       "      <td>1.679154</td>\n",
       "      <td>125.177118</td>\n",
       "      <td>...</td>\n",
       "      <td>29.296129</td>\n",
       "      <td>30.029667</td>\n",
       "      <td>29.726129</td>\n",
       "      <td>28.730000</td>\n",
       "      <td>27.662581</td>\n",
       "      <td>27.402581</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>28.895806</td>\n",
       "      <td>30.182333</td>\n",
       "      <td>29.827097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>32023</td>\n",
       "      <td>2018-06</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>0.4541</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>0.3346</td>\n",
       "      <td>IDN</td>\n",
       "      <td>1.671353</td>\n",
       "      <td>125.133216</td>\n",
       "      <td>...</td>\n",
       "      <td>29.296129</td>\n",
       "      <td>30.029667</td>\n",
       "      <td>29.726129</td>\n",
       "      <td>28.730000</td>\n",
       "      <td>27.662581</td>\n",
       "      <td>27.402581</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>28.895806</td>\n",
       "      <td>30.182333</td>\n",
       "      <td>29.827097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>32012</td>\n",
       "      <td>2018-06</td>\n",
       "      <td>0.0587</td>\n",
       "      <td>0.5438</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>IDN</td>\n",
       "      <td>1.734514</td>\n",
       "      <td>125.150193</td>\n",
       "      <td>...</td>\n",
       "      <td>29.296129</td>\n",
       "      <td>30.029667</td>\n",
       "      <td>29.726129</td>\n",
       "      <td>28.730000</td>\n",
       "      <td>27.662581</td>\n",
       "      <td>27.402581</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>28.895806</td>\n",
       "      <td>30.182333</td>\n",
       "      <td>29.827097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>32010</td>\n",
       "      <td>2018-06</td>\n",
       "      <td>0.0373</td>\n",
       "      <td>0.6490</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.2908</td>\n",
       "      <td>IDN</td>\n",
       "      <td>1.836848</td>\n",
       "      <td>125.146803</td>\n",
       "      <td>...</td>\n",
       "      <td>29.296129</td>\n",
       "      <td>30.029667</td>\n",
       "      <td>29.726129</td>\n",
       "      <td>28.730000</td>\n",
       "      <td>27.662581</td>\n",
       "      <td>27.402581</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>28.895806</td>\n",
       "      <td>30.182333</td>\n",
       "      <td>29.827097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>32011</td>\n",
       "      <td>2018-06</td>\n",
       "      <td>0.0815</td>\n",
       "      <td>0.6142</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.2477</td>\n",
       "      <td>IDN</td>\n",
       "      <td>1.773760</td>\n",
       "      <td>125.130850</td>\n",
       "      <td>...</td>\n",
       "      <td>29.296129</td>\n",
       "      <td>30.029667</td>\n",
       "      <td>29.726129</td>\n",
       "      <td>28.730000</td>\n",
       "      <td>27.662581</td>\n",
       "      <td>27.402581</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>28.895806</td>\n",
       "      <td>30.182333</td>\n",
       "      <td>29.827097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416 rows  1292 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     transectid surveydate  pr_hard_coral  pr_algae  pr_soft_coral  \\\n",
       "0         10001    2012-09         0.1856    0.3724         0.2710   \n",
       "1         10002    2012-09         0.1364    0.4766         0.3079   \n",
       "2         10003    2012-09         0.2475    0.5653         0.0747   \n",
       "3         10004    2012-09         0.1242    0.5706         0.0279   \n",
       "4         10005    2012-09         0.0781    0.7894         0.0096   \n",
       "..          ...        ...            ...       ...            ...   \n",
       "411       32022    2018-06         0.0664    0.7374         0.0306   \n",
       "412       32023    2018-06         0.1148    0.4541         0.0658   \n",
       "413       32012    2018-06         0.0587    0.5438         0.0504   \n",
       "414       32010    2018-06         0.0373    0.6490         0.0072   \n",
       "415       32011    2018-06         0.0815    0.6142         0.0238   \n",
       "\n",
       "     pr_oth_invert  pr_other country  lat_start   lng_start  ... SST_2020-03  \\\n",
       "0           0.0010    0.1700     AUS -16.189023  145.898104  ...   29.131290   \n",
       "1           0.0020    0.0771     AUS -16.189303  145.898254  ...   29.131290   \n",
       "2           0.0207    0.0917     AUS -16.175768  145.891676  ...   29.131290   \n",
       "3           0.0023    0.2748     AUS -16.536645  147.806796  ...   29.189032   \n",
       "4           0.0029    0.1201     AUS -16.529216  147.802582  ...   29.189032   \n",
       "..             ...       ...     ...        ...         ...  ...         ...   \n",
       "411         0.0368    0.1291     IDN   1.679154  125.177118  ...   29.296129   \n",
       "412         0.0307    0.3346     IDN   1.671353  125.133216  ...   29.296129   \n",
       "413         0.0512    0.2962     IDN   1.734514  125.150193  ...   29.296129   \n",
       "414         0.0157    0.2908     IDN   1.836848  125.146803  ...   29.296129   \n",
       "415         0.0328    0.2477     IDN   1.773760  125.130850  ...   29.296129   \n",
       "\n",
       "     SST_2020-04  SST_2020-05  SST_2020-06  SST_2020-07  SST_2020-08  \\\n",
       "0      28.149000    26.596774    25.201333    25.066452    24.992258   \n",
       "1      28.149000    26.596774    25.201333    25.066452    24.992258   \n",
       "2      28.149000    26.596774    25.201333    25.066452    24.992258   \n",
       "3      28.035333    26.689355    25.959667    25.159355    25.284839   \n",
       "4      28.035333    26.689355    25.959667    25.159355    25.284839   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "411    30.029667    29.726129    28.730000    27.662581    27.402581   \n",
       "412    30.029667    29.726129    28.730000    27.662581    27.402581   \n",
       "413    30.029667    29.726129    28.730000    27.662581    27.402581   \n",
       "414    30.029667    29.726129    28.730000    27.662581    27.402581   \n",
       "415    30.029667    29.726129    28.730000    27.662581    27.402581   \n",
       "\n",
       "     SST_2020-09  SST_2020-10  SST_2020-11  SST_2020-12  \n",
       "0      25.365333    26.007742    27.440667    28.819677  \n",
       "1      25.365333    26.007742    27.440667    28.819677  \n",
       "2      25.365333    26.007742    27.440667    28.819677  \n",
       "3      25.236000    25.908065    27.396333    28.501613  \n",
       "4      25.236000    25.908065    27.396333    28.501613  \n",
       "..           ...          ...          ...          ...  \n",
       "411    27.666667    28.895806    30.182333    29.827097  \n",
       "412    27.666667    28.895806    30.182333    29.827097  \n",
       "413    27.666667    28.895806    30.182333    29.827097  \n",
       "414    27.666667    28.895806    30.182333    29.827097  \n",
       "415    27.666667    28.895806    30.182333    29.827097  \n",
       "\n",
       "[416 rows x 1292 columns]"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PAR_paths = glob.glob(\"../Data/Environmental_data/PAR_month/requested_files/A20*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PAR = []\n",
    "def fetch_data_PAR(paths):\n",
    "    for i in range(len(df_PAR_paths)):\n",
    "        df_PAR.append(xr.open_dataset(paths[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_data_PAR(df_PAR_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PAR_pre(ds_PAR_list, df, Survey_dates):\n",
    "    df_conc = []\n",
    "    i = 0\n",
    "    for date in Survey_dates:\n",
    "        ds_PAR_list[i] = ds_PAR_list[i].drop(labels = \"palette\")\n",
    "        df_part = df[df[\"surveydate\"] == date]\n",
    "        df1 = df_part.copy()\n",
    "        df1.set_index([\"lat\", \"lon\"],inplace = True)\n",
    "        xr_merged = xr.Dataset.from_dataframe(df1)\n",
    "        # Keep interesting lat/long\n",
    "        \n",
    "        long_ = [xr_merged[\"lon\"].values]\n",
    "        latg_ = [xr_merged[\"lat\"].values]\n",
    "        \n",
    "        df_par_near = ds_PAR_list[i].sel(lon=long_[0], lat=latg_[0], method='nearest')\n",
    "        same_coord = df_par_near.assign_coords(lon = long_[0], lat = latg_[0])\n",
    "        xr_merged_ = xr_merged.merge(same_coord, join = \"inner\")\n",
    "        \n",
    "        df_frame = xr_merged_.to_dataframe()\n",
    "        df_ = df_frame.dropna().reset_index()\n",
    "        df_conc.append(df_)\n",
    "        i = i + 1\n",
    "    return pd.concat(df_conc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "One or more of the specified variables cannot be found in this dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-519-181fc42d68b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_Survey_PAR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPAR_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_PAR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_Survey_merged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSurvey_dates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-515-48840f87882c>\u001b[0m in \u001b[0;36mPAR_pre\u001b[0;34m(ds_PAR_list, df, Survey_dates)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSurvey_dates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mds_PAR_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_PAR_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"palette\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mdf_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"surveydate\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_part\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, dim, errors, **labels_kwargs)\u001b[0m\n\u001b[1;32m   4047\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4048\u001b[0m             )\n\u001b[0;32m-> 4049\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4051\u001b[0m             warnings.warn(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mdrop_vars\u001b[0;34m(self, names, errors)\u001b[0m\n\u001b[1;32m   4006\u001b[0m             \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4007\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4008\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_all_in_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4010\u001b[0m         \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m_assert_all_in_dataset\u001b[0;34m(self, names, virtual_okay)\u001b[0m\n\u001b[1;32m   3976\u001b[0m             \u001b[0mbad_names\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvirtual_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3977\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbad_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3978\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   3979\u001b[0m                 \u001b[0;34m\"One or more of the specified variables \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3980\u001b[0m                 \u001b[0;34m\"cannot be found in this dataset\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: One or more of the specified variables cannot be found in this dataset"
     ]
    }
   ],
   "source": [
    "df_Survey_PAR = PAR_pre(df_PAR, df_Survey_merged, Survey_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Survey_PAR.to_csv(\"../Data/Environmental_data/df_env_merged_par.csv\", index = False)\n",
    "df_Survey_merged = pd.read_csv(\"../Data/Environmental_data/df_env_merged_par.csv\")\n",
    "dp.geo_loads(df_Survey_merged)\n",
    "df_Survey_merged = pf.make_geo_frame(df_Survey_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance to port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile = '../Data/Environmental_data/distance-from-port-v1.tiff'\n",
    "outputfile = '../Data/Environmental_data/distance-from-port.nc'\n",
    "# The following command will convert the geoTIFF to a netCDF\n",
    "ds = gdal.Translate(outputfile, inputfile, format='NetCDF')\n",
    "\n",
    "ds_port_dist = xr.open_dataset(\"../Data/Environmental_data/distance-from-port.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounds of coordinates for Pacific\n",
    "latbounds = [-24, 4]\n",
    "lonbounds = [110, 160]\n",
    "lats = ds_port_dist.variables[\"lat\"][:]\n",
    "lons = ds_port_dist.variables[\"lon\"][:]\n",
    "# latitude lower and upper index\n",
    "latli = np.argmin( np.abs( lats - latbounds[0] ).values )\n",
    "latui = np.argmin( np.abs( lats - latbounds[1] ).values ) \n",
    "# longitude lower and upper index\n",
    "lonli = np.argmin( np.abs( lons - lonbounds[0] ).values )\n",
    "lonui = np.argmin( np.abs( lons - lonbounds[1] ).values )  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for the given coordinates\n",
    "PortSubset = ds_port_dist.variables['Band1'][latli:latui , lonli:lonui ] \n",
    "\n",
    "# Dataset with the chlor amongst the different coordinates\n",
    "ds_sub_port = xr.Dataset(data_vars={\"Port_dist\": PortSubset}, coords = {\"lon\":ds_port_dist[\"lon\"][lonli:lonui], \"lat\": ds_port_dist[\"lat\"][latli:latui]})\n",
    "\n",
    "df_port = ds_sub_port.to_dataframe()\n",
    "\n",
    "\n",
    "df_port.reset_index(inplace = True)\n",
    "\n",
    "\n",
    "# remove the Nan values, so that it automatically takes the other ones that are closest\n",
    "df_port = df_port.dropna(axis = 0)\n",
    "\n",
    "\n",
    "gdf_port = gpd.GeoDataFrame(df_port, geometry=gpd.points_from_xy(df_port.lat, df_port.lon))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_port.drop(columns = [\"lat\", \"lon\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Closest_port = dp.nearest_neighbor(df_Survey_merged, gdf_port, return_dist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Port_dist</th>\n",
       "      <th>geometry</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.447258</td>\n",
       "      <td>POINT (-18.830 147.650)</td>\n",
       "      <td>404.245121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63.403625</td>\n",
       "      <td>POINT (-18.810 147.670)</td>\n",
       "      <td>416.935248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.639008</td>\n",
       "      <td>POINT (-18.670 147.720)</td>\n",
       "      <td>520.150084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.634659</td>\n",
       "      <td>POINT (-18.660 147.720)</td>\n",
       "      <td>601.594003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82.516258</td>\n",
       "      <td>POINT (-18.590 147.570)</td>\n",
       "      <td>533.509550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>34.628056</td>\n",
       "      <td>POINT (-8.220 125.530)</td>\n",
       "      <td>174.526710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>35.853439</td>\n",
       "      <td>POINT (-8.210 125.620)</td>\n",
       "      <td>321.991143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>39.474037</td>\n",
       "      <td>POINT (-8.180 125.640)</td>\n",
       "      <td>442.709526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1.099620</td>\n",
       "      <td>POINT (-8.540 125.610)</td>\n",
       "      <td>386.734287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3.127721</td>\n",
       "      <td>POINT (-8.520 125.620)</td>\n",
       "      <td>457.549400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Port_dist                 geometry    distance\n",
       "0    60.447258  POINT (-18.830 147.650)  404.245121\n",
       "1    63.403625  POINT (-18.810 147.670)  416.935248\n",
       "2    79.639008  POINT (-18.670 147.720)  520.150084\n",
       "3    80.634659  POINT (-18.660 147.720)  601.594003\n",
       "4    82.516258  POINT (-18.590 147.570)  533.509550\n",
       "..         ...                      ...         ...\n",
       "411  34.628056   POINT (-8.220 125.530)  174.526710\n",
       "412  35.853439   POINT (-8.210 125.620)  321.991143\n",
       "413  39.474037   POINT (-8.180 125.640)  442.709526\n",
       "414   1.099620   POINT (-8.540 125.610)  386.734287\n",
       "415   3.127721   POINT (-8.520 125.620)  457.549400\n",
       "\n",
       "[416 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Closest_port.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Closest_port' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3ad13c2856cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_Survey_merged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"closest_port\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClosest_port\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"distance\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_Survey_merged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Data/Environmental_data/df_env_merged.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_Survey_merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Data/Environmental_data/df_env_merged.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Closest_port' is not defined"
     ]
    }
   ],
   "source": [
    "df_Survey_merged[\"closest_port\"] = Closest_port[\"distance\"]\n",
    "\n",
    "df_Survey_merged.to_csv(\"../Data/Environmental_data/df_env_merged.csv\", index = False)\n",
    "\n",
    "df_Survey_merged = pd.read_csv(\"../Data/Environmental_data/df_env_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_Survey_merged = pd.read_csv(\"../Data/Environmental_data/df_env_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extent = df_extended[df_extended.columns[12:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Survey_merged_extended = pd.concat([df_Survey_merged, df_extent], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Survey_merged_extended.to_csv(\"../Data/Environmental_data/df_env_merged_extended_5_5.csv\", index = False)\n",
    "\n",
    "df_Survey_merged_extended = pd.read_csv(\"../Data/Environmental_data/df_env_merged_extended_5_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
